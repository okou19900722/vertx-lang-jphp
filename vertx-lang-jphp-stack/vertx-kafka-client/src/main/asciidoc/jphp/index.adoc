= Vert.x Kafka client
:toc: left

This component provides a Kafka client for reading and sending messages from/to an link:https://kafka.apache.org/[Apache Kafka] cluster.

As consumer, the API provides methods for subscribing to a topic partition receiving
messages asynchronously or reading them as a stream (even with the possibility to pause/resume the stream).

As producer, the API provides methods for sending message to a topic partition like writing on a stream.

WARNING: this module has the tech preview status, this means the API can change between versions.

== Using the Vert.x Kafka client

To use this component, add the following dependency to the dependencies section of your build descriptor:

* Maven (in your `pom.xml`):

[source,xml,subs="+attributes"]
----
<dependency>
 <groupId>io.vertx</groupId>
 <artifactId>vertx-kafka-client</artifactId>
 <version>${maven.version}</version>
</dependency>
----

* Gradle (in your `build.gradle` file):

[source,groovy,subs="+attributes"]
----
compile io.vertx:vertx-kafka-client:${maven.version}
----

== Creating Kafka clients

Creating consumers and producers is quite similar and on how it works using the native Kafka client library.

They need to be configured with a bunch of properties as described in the official
Apache Kafka documentation, for the link:https://kafka.apache.org/documentation/#newconsumerconfigs[consumer] and
for the link:https://kafka.apache.org/documentation/#producerconfigs[producer].

To achieve that, a map can be configured with such properties passing it to one of the
static creation methods exposed by `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html[KafkaConsumer]` and
`link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.producer.KafkaProducer.html[KafkaProducer]`

[source,php]
----
<?php
    use io\vertx\jphp\kafka\client\consumer\KafkaConsumer;

    // creating the consumer using map config
    $config = array();
    $config["bootstrap.servers"] = "localhost:9092";
    $config["key.deserializer"] = "org.apache.kafka.common.serialization.StringDeserializer";
    $config["value.deserializer"] = "org.apache.kafka.common.serialization.StringDeserializer";
    $config["group.id"] = "my_group";
    $config["auto.offset.reset"] = "earliest";
    $config["enable.auto.commit"] = "false";

    // use consumer for interacting with Apache Kafka
    $consumer = KafkaConsumer::create($vertx, $config);

----

In the above example, a `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html[KafkaConsumer]` instance is created using
a map instance in order to specify the Kafka nodes list to connect (just one) and
the deserializers to use for getting key and value from each received message.

Likewise a producer can be created

[source,php]
----
<?php
    use io\vertx\jphp\kafka\client\producer\KafkaProducer;

    // creating the producer using map and class types for key and value serializers/deserializers
    $config = array();
    $config["bootstrap.servers"] = "localhost:9092";
    $config["key.serializer"] = "org.apache.kafka.common.serialization.StringSerializer";
    $config["value.serializer"] = "org.apache.kafka.common.serialization.StringSerializer";
    $config["acks"] = "1";

    // use producer for interacting with Apache Kafka
    $producer = KafkaProducer::create($vertx, $config);

----

ifdef::java,groovy,kotlin[]
Another way is to use a `Properties` instance instead of the map.

[source,php]
----
<?php
    use io\vertx\jphp\kafka\client\consumer\KafkaConsumer;

    // creating the consumer using properties config
    $config = Java::type("java.util.Properties").newInstance();
    $config->put(Java::type("org.apache.kafka.clients.consumer.ConsumerConfig")->BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
    $config->put(Java::type("org.apache.kafka.clients.consumer.ConsumerConfig")->KEY_DESERIALIZER_CLASS_CONFIG, Java::type("org.apache.kafka.common.serialization.StringDeserializer")->class);
    $config->put(Java::type("org.apache.kafka.clients.consumer.ConsumerConfig")->VALUE_DESERIALIZER_CLASS_CONFIG, Java::type("org.apache.kafka.common.serialization.StringDeserializer")->class);
    $config->put(Java::type("org.apache.kafka.clients.consumer.ConsumerConfig")->GROUP_ID_CONFIG, "my_group");
    $config->put(Java::type("org.apache.kafka.clients.consumer.ConsumerConfig")->AUTO_OFFSET_RESET_CONFIG, "earliest");
    $config->put(Java::type("org.apache.kafka.clients.consumer.ConsumerConfig")->ENABLE_AUTO_COMMIT_CONFIG, "false");

    // use consumer for interacting with Apache Kafka
    $consumer = KafkaConsumer::create($vertx, $config);

----

More advanced creation methods allow to specify the class type for the key and the value used for sending messages
or provided by received messages; this is a way for setting the key and value serializers/deserializers instead of
using the related properties for that

[source,php]
----
<?php
    use io\vertx\jphp\kafka\client\producer\KafkaProducer;

    // creating the producer using map and class types for key and value serializers/deserializers
    $config = Java::type("java.util.Properties").newInstance();
    $config->put(Java::type("org.apache.kafka.clients.producer.ProducerConfig")->BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
    $config->put(Java::type("org.apache.kafka.clients.producer.ProducerConfig")->ACKS_CONFIG, "1");

    // use producer for interacting with Apache Kafka
    $producer = KafkaProducer::create($vertx, $config, Java::type("java.lang.String")->class, Java::type("java.lang.String")->class);

----

Here the `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.producer.KafkaProducer.html[KafkaProducer]` instance is created in using a `Properties` for
specifying Kafka nodes list to connect (just one) and the acknowledgment mode; the key and value deserializers are
specified as parameters of `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.producer.KafkaProducer.html#method_create[KafkaProducer::create]`.
endif::[]

== Receiving messages from a topic joining a consumer group

In order to start receiving messages from Kafka topics, the consumer can use the
`link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html#method_subscribe[subscribe]`method for
subscribing to a set of topics being part of a consumer group (specified by the properties on creation).

You also need to register a handler for handling incoming messages using the
`link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html#method_handler[handler]`.

[source,php]
----
<?php

    // register the handler for incoming messages
    $consumer->handler(function ($record) {
        echo "Processing key=".$record->key().",value=".$record->value().",partition=".$record->partition().",offset=".$record->offset()."\n";
    });

    // subscribe to several topics
    $topics = Java::type("java.util.HashSet").newInstance();
    $topics->add("topic1");
    $topics->add("topic2");
    $topics->add("topic3");
    $consumer->subscribe($topics);

    // or just subscribe to a single topic
    $consumer->subscribe("a-single-topic");

----

The handler can be registered before or after the call to `subscribe()`; messages won't be consumed until both
methods have been called. This allows you to call `subscribe()`, then `seek()` and finally `handler()` in
order to only consume messages starting from a particular offset, for example.

A handler can also be passed during subscription to be aware of the subscription result and being notified when the operation
is completed.

[source,php]
----
<?php

    // register the handler for incoming messages
    $consumer->handler(function ($record) {
        echo "Processing key=".$record->key().",value=".$record->value().",partition=".$record->partition().",offset=".$record->offset()."\n";
    });

    // subscribe to several topics
    $topics = Java::type("java.util.HashSet").newInstance();
    $topics->add("topic1");
    $topics->add("topic2");
    $topics->add("topic3");
    $consumer->subscribe($topics, function ($ar, $ar_err) {
        if ($ar != null) {
            echo "subscribed\n";
        } else {
            echo "Could not subscribe ".$ar_err->getMessage()."\n";
        };
    });

    // or just subscribe to a single topic
    $consumer->subscribe("a-single-topic", function ($ar, $ar_err) {
        if ($ar != null) {
            echo "subscribed\n";
        } else {
            echo "Could not subscribe ".$ar_err->getMessage()."\n";
        };
    });

----

Using the consumer group way, the Kafka cluster assigns partitions to the consumer taking into account other connected
consumers in the same consumer group, so that partitions can be spread across them.

The Kafka cluster handles partitions re-balancing when a consumer leaves the group (so assigned partitions are free
to be assigned to other consumers) or a new consumer joins the group (so it wants partitions to read from).

You can register handlers on a `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html[KafkaConsumer]` to be notified
of the partitions revocations and assignments by the Kafka cluster using
`link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html#method_partitionsRevokedHandler[partitionsRevokedHandler]`and
`link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html#method_partitionsAssignedHandler[partitionsAssignedHandler]`.

[source,php]
----
<?php

    // register the handler for incoming messages
    $consumer->handler(function ($record) {
        echo "Processing key=".$record->key().",value=".$record->value().",partition=".$record->partition().",offset=".$record->offset()."\n";
    });

    // registering handlers for assigned and revoked partitions
    $consumer->partitionsAssignedHandler(function ($topicPartitions) {

        echo "Partitions assigned\n";
        foreach($topicPartitions as $topicPartition) {
            echo "$topicPartition["topic"]. .$topicPartition["partition"]"."\n";
        };
    });

    $consumer->partitionsRevokedHandler(function ($topicPartitions) {

        echo "Partitions revoked\n";
        foreach($topicPartitions as $topicPartition) {
            echo "$topicPartition["topic"]. .$topicPartition["partition"]"."\n";
        };
    });

    // subscribes to the topic
    $consumer->subscribe("test", function ($ar, $ar_err) {

        if ($ar != null) {
            echo "Consumer subscribed\n";
        };
    });

----

After joining a consumer group for receiving messages, a consumer can decide to leave the consumer group in order to
not get messages anymore using `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html#method_unsubscribe[unsubscribe]`

[source,php]
----
<?php

    // consumer is already member of a consumer group

    // unsubscribing request
    $consumer->unsubscribe();

----

You can add an handler to be notified of the result

[source,php]
----
<?php

    // consumer is already member of a consumer group

    // unsubscribing request
    $consumer->unsubscribe(function ($ar, $ar_err) {

        if ($ar != null) {
            echo "Consumer unsubscribed\n";
        };
    });

----

== Receiving messages from a topic requesting specific partitions

Besides being part of a consumer group for receiving messages from a topic, a consumer can ask for a specific
topic partition. When the consumer is not part part of a consumer group the overall application cannot
rely on the re-balancing feature.

You can use `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html#method_assign[assign]`
in order to ask for specific partitions.

[source,php]
----
<?php

    // register the handler for incoming messages
    $consumer->handler(function ($record) {
        echo "key=".$record->key().",value=".$record->value().",partition=".$record->partition().",offset=".$record->offset()."\n";
    });

    //
    $topicPartitions = Java::type("java.util.HashSet").newInstance();
    $topicPartitions->add(array(
        "topic" => "test",
        "partition" => 0
    ));

    // requesting to be assigned the specific partition
    $consumer->assign($topicPartitions, function ($done, $done_err) {

        if ($done != null) {
            echo "Partition assigned\n";

            // requesting the assigned partitions
            $consumer->assignment(function ($done1, $done1_err) {

                if ($done1 != null) {

                    foreach($done1 as $topicPartition) {
                        echo "$topicPartition["topic"]. .$topicPartition["partition"]"."\n";
                    };
                };
            });
        };
    });

----

As with `subscribe()`, the handler can be registered before or after the call to `assign()`;
messages won't be consumed until both methods have been called. This allows you to call
`assign()`, then `seek()` and finally `handler()` in
order to only consume messages starting from a particular offset, for example.

Calling `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html#method_assignment[assignment]` provides
the list of the current assigned partitions.

== Changing the subscription or assignment

You can change the subscribed topics, or assigned partitions after you have started to consume messages, simply
by calling `subscribe()` or `assign()` again.

Note that due to internal buffering of messages it is possible that the record handler will continue to
observe messages from the old subscription or assignment _after_ the `subscribe()` or `assign()`
method's completion handler has been called. This is not the case for messages observed by the batch handler:
Once the completion handler has been called it will only observe messages read from the subscription or assignment.

== Getting topic partition information

You can call the `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html#method_partitionsFor[partitionsFor]` to get information about
partitions for a specified topic

[source,php]
----
<?php

    // asking partitions information about specific topic
    $consumer->partitionsFor("test", function ($ar, $ar_err) {

        if ($ar != null) {

            foreach($ar as $partitionInfo) {
                echo $partitionInfo."\n";
            };
        };
    });

----

In addition `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html#method_listTopics[listTopics]` provides all available topics
with related partitions

[source,php]
----
<?php

    // asking information about available topics and related partitions
    $consumer->listTopics(function ($ar, $ar_err) {

        if ($ar != null) {

            $map = $ar;
            foreach ($map as $topic => $partitions) {
                echo "topic = ".$topic."\n";
                echo "partitions = ".$map[$topic]."\n";
            }
            ;
        };
    });

----

== Manual offset commit

In Apache Kafka the consumer is in charge to handle the offset of the last read message.

This is executed by the commit operation executed automatically every time a bunch of messages are read
from a topic partition. The configuration parameter `enable.auto.commit` must be set to `true` when the
consumer is created.

Manual offset commit, can be achieved with `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html#method_commit[commit]`.
It can be used to achieve _at least once_ delivery to be sure that the read messages are processed before committing
the offset.

[source,php]
----
<?php

    // consumer is processing read messages

    // committing offset of the last read message
    $consumer->commit(function ($ar, $ar_err) {

        if ($ar != null) {
            echo "Last read message offset committed\n";
        };
    });

----

== Seeking in a topic partition

Apache Kafka can retain messages for a long period of time and the consumer can seek inside a topic partition
and obtain arbitrary access to the messages.

You can use `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html#method_seek[seek]` to change the offset for reading at a specific
position

[source,php]
----
<?php

    $topicPartition = array(
        "topic" => "test",
        "partition" => 0
    );

    // seek to a specific offset
    $consumer->seek($topicPartition, 10, function ($done, $done_err) {

        if ($done != null) {
            echo "Seeking done\n";
        };
    });


----

When the consumer needs to re-read the stream from the beginning, it can use `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html#method_seekToBeginning[seekToBeginning]`

[source,php]
----
<?php

    $topicPartition = array(
        "topic" => "test",
        "partition" => 0
    );

    // seek to the beginning of the partition
    $consumer->seekToBeginning(Java::type("java.util.Collections")->singleton($topicPartition), function ($done, $done_err) {

        if ($done != null) {
            echo "Seeking done\n";
        };
    });

----

Finally `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html#method_seekToEnd[seekToEnd]` can be used to come back at the end of the partition

[source,php]
----
<?php

    $topicPartition = array(
        "topic" => "test",
        "partition" => 0
    );

    // seek to the end of the partition
    $consumer->seekToEnd(Java::type("java.util.Collections")->singleton($topicPartition), function ($done, $done_err) {

        if ($done != null) {
            echo "Seeking done\n";
        };
    });

----

Note that due to internal buffering of messages it is possible that the record handler will continue to
observe messages read from the original offset for a time _after_ the `seek*()` method's completion
handler has been called. This is not the case for messages observed by the batch handler: Once the
`seek*()` completion handler has been called it will only observe messages read from the new offset.

== Offset lookup

You can use the beginningOffsets API introduced in Kafka 0.10.1.1 to get the first offset
for a given partition. In contrast to `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html#method_seekToBeginning[seekToBeginning]`,
it does not change the consumer's offset.

[source,php]
----
<?php
    $topicPartitions = Java::type("java.util.HashSet").newInstance();
    $topicPartition = array(
        "topic" => "test",
        "partition" => 0
    );
    $topicPartitions->add($topicPartition);

    $consumer->beginningOffsets($topicPartitions, function ($done, $done_err) {
        if ($done != null) {
            $results = $done;
            foreach ($results as $topic => $beginningOffset) {
                echo "Beginning offset for topic=.$topic["topic"]., partition=.$topic["partition"]., beginningOffset=".$beginningOffset."\n"}
            ;
        };
    });

    // Convenience method for single-partition lookup
    $consumer->beginningOffsets($topicPartition, function ($done, $done_err) {
        if ($done != null) {
            $beginningOffset = $done;
            echo "Beginning offset for topic=.$topicPartition["topic"]., partition=.$topicPartition["partition"]., beginningOffset=".$beginningOffset."\n";
        };
    });


----

You can use the endOffsets API introduced in Kafka 0.10.1.1 to get the last offset
for a given partition. In contrast to `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html#method_seekToEnd[seekToEnd]`,
it does not change the consumer's offset.

[source,php]
----
<?php
    $topicPartitions = Java::type("java.util.HashSet").newInstance();
    $topicPartition = array(
        "topic" => "test",
        "partition" => 0
    );
    $topicPartitions->add($topicPartition);

    $consumer->endOffsets($topicPartitions, function ($done, $done_err) {
        if ($done != null) {
            $results = $done;
            foreach ($results as $topic => $endOffset) {
                echo "End offset for topic=.$topic["topic"]., partition=.$topic["partition"]., endOffset=".$endOffset."\n"}
            ;
        };
    });

    // Convenience method for single-partition lookup
    $consumer->endOffsets($topicPartition, function ($done, $done_err) {
        if ($done != null) {
            $endOffset = $done;
            echo "End offset for topic=.$topicPartition["topic"]., partition=.$topicPartition["partition"]., endOffset=".$endOffset."\n";
        };
    });

----

You can use the offsetsForTimes API introduced in Kafka 0.10.1.1 to look up an offset by
timestamp, i.e. search parameter is an epoch timestamp and the call returns the lowest offset
with ingestion timestamp >= given timestamp.

[source,php]
----
<?php
    $topicPartitionsWithTimestamps = array();
    $topicPartition = array(
        "topic" => "test",
        "partition" => 0
    );

    // We are interested in the offset for data ingested 60 seconds ago
    $timestamp = ();

    $topicPartitionsWithTimestamps[$topicPartition] = $timestamp;
    $consumer->offsetsForTimes($topicPartitionsWithTimestamps, function ($done, $done_err) {
        if ($done != null) {
            $results = $done;
            foreach ($results as $topic => $offset) {
                echo "Offset for topic=.$topic["topic"]., partition=.$topic["partition"].\n, timestamp=".$timestamp.", offset=.$offset["offset"]., offsetTimestamp=.$offset["timestamp"]"."\n"}
            ;

        };
    });

    // Convenience method for single-partition lookup
    $consumer->offsetsForTimes($topicPartition, $timestamp, function ($done, $done_err) {
        if ($done != null) {
            $offsetAndTimestamp = $done;
            echo "Offset for topic=.$topicPartition["topic"]., partition=.$topicPartition["partition"].\n, timestamp=".$timestamp.", offset=.$offsetAndTimestamp["offset"]., offsetTimestamp=.$offsetAndTimestamp["timestamp"]"."\n";

        };
    });

----
== Message flow control

A consumer can control the incoming message flow and pause/resume the read operation from a topic, e.g it
can pause the message flow when it needs more time to process the actual messages and then resume
to continue message processing.

To achieve that you can use `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html#method_pause[pause]` and
`link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html#method_resume[resume]`.

In the case of the partition-specific pause and resume it is possible that the record handler will continue to
observe messages from a paused partition for a time _after_ the `pause()` method's completion
handler has been called. This is not the case for messages observed by the batch handler: Once the
`pause()` completion handler has been called it will only observe messages from those partitions which
rare not paused.

[source,php]
----
<?php

    $topicPartition = array(
        "topic" => "test",
        "partition" => 0
    );

    // registering the handler for incoming messages
    $consumer->handler(function ($record) {
        echo "key=".$record->key().",value=".$record->value().",partition=".$record->partition().",offset=".$record->offset()."\n";

        // i.e. pause/resume on partition 0, after reading message up to offset 5
        if (($record->partition() == 0) && ($record->offset() == 5)) {

            // pause the read operations
            $consumer->pause($topicPartition, function ($ar, $ar_err) {

                if ($ar != null) {

                    echo "Paused\n";

                    // resume read operation after a specific time
                    $vertx->setTimer(5000, function ($timeId) {

                        // resumi read operations
                        $consumer->resume($topicPartition);
                    });
                };
            });
        };
    });

----

== Closing a consumer

Call close to close the consumer. Closing the consumer closes any open connections and releases all consumer resources.

The close is actually asynchronous and might not complete until some time after the call has returned. If you want to be notified
when the actual close has completed then you can pass in a handler.

This handler will then be called when the close has fully completed.

[source,php]
----
<?php
    $consumer->close(function ($res, $res_err) {
        if ($res != null) {
            echo "Consumer is now closed\n";
        } else {
            echo "close failed\n";
        };
    });

----

== Sending messages to a topic

You can use  `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.producer.KafkaProducer.html#method_write[write]` to send messages (records) to a topic.

The simplest way to send a message is to specify only the destination topic and the related value, omitting its key
or partition, in this case the messages are sent in a round robin fashion across all the partitions of the topic.

[source,php]
----
<?php
    use io\vertx\jphp\kafka\client\producer\KafkaProducerRecord;

    for ($i = 0; $i < 5; $i++) {

        // only topic and message value are specified, round robin on destination partitions
        $record = KafkaProducerRecord::create("test", "message_".$i);

        $producer->write($record);
    };

----

You can receive message sent metadata like its topic, its destination partition and its assigned offset.

[source,php]
----
<?php
    use io\vertx\jphp\kafka\client\producer\KafkaProducerRecord;

    for ($i = 0; $i < 5; $i++) {

        // only topic and message value are specified, round robin on destination partitions
        $record = KafkaProducerRecord::create("test", "message_".$i);

        $producer->write($record, function ($done, $done_err) {

            if ($done != null) {

                $recordMetadata = $done;
                echo "Message ".$record->value()." written on topic=.$recordMetadata["topic"]., partition=.$recordMetadata["partition"]., offset=.$recordMetadata["offset"]"."\n";
            };

        });
    };


----

When you need to assign a partition to a message, you can specify its partition identifier
or its key

[source,php]
----
<?php
    use io\vertx\jphp\kafka\client\producer\KafkaProducerRecord;

    for ($i = 0; $i < 10; $i++) {

        // a destination partition is specified
        $record = KafkaProducerRecord::create("test", null, "message_".$i, 0);

        $producer->write($record);
    };

----

Since the producers identifies the destination using key hashing, you can use that to guarantee that all
messages with the same key are sent to the same partition and retain the order.

[source,php]
----
<?php
    use io\vertx\jphp\kafka\client\producer\KafkaProducerRecord;

    for ($i = 0; $i < 10; $i++) {

        // i.e. defining different keys for odd and even messages
        $key = $i % 2;

        // a key is specified, all messages with same key will be sent to the same partition
        $record = KafkaProducerRecord::create("test", Java::type("java.lang.String")->valueOf($key), "message_".$i);

        $producer->write($record);
    };

----

NOTE: the shared producer is created on the first `createShared` call and its configuration is defined at this moment,
shared producer usage must use the same configuration.

== Sharing a producer

Sometimes you want to share the same producer from within several verticles or contexts.

Calling `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.producer.KafkaProducer.html#method_createShared[KafkaProducer::createShared]`
returns a producer that can be shared safely.

[source,php]
----
<?php
    use io\vertx\jphp\kafka\client\producer\KafkaProducer;

    // Create a shared producer identified by 'the-producer'
    $producer1 = KafkaProducer::createShared($vertx, "the-producer", $config);

    // Sometimes later you can close it
    $producer1->close();

----

The same resources (thread, connection) will be shared between the producer returned by this method.

When you are done with the producer, just close it, when all shared producers are closed, the resources will
be released for you.

== Closing a producer

Call close to close the producer. Closing the producer closes any open connections and releases all producer resources.

The close is actually asynchronous and might not complete until some time after the call has returned. If you want to be notified
when the actual close has completed then you can pass in a handler.

This handler will then be called when the close has fully completed.

[source,php]
----
<?php
    $producer->close(function ($res, $res_err) {
        if ($res != null) {
            echo "Producer is now closed\n";
        } else {
            echo "close failed\n";
        };
    });

----

== Getting topic partition information

You can call the `link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.producer.KafkaProducer.html#method_partitionsFor[partitionsFor]` to get information about
partitions for a specified topic:

[source,php]
----
<?php

    // asking partitions information about specific topic
    $producer->partitionsFor("test", function ($ar, $ar_err) {

        if ($ar != null) {

            foreach($ar as $partitionInfo) {
                echo $partitionInfo."\n";
            };
        };
    });

----

== Handling errors

Errors handling (e.g timeout) between a Kafka client (consumer or producer) and the Kafka cluster is done using
`link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.consumer.KafkaConsumer.html#method_exceptionHandler[exceptionHandler]`or
`link:https://vertx.okou.tk/phpdoc/vertx-kafka-client-jphp/classes/io.vertx.jphp.kafka.client.producer.KafkaProducer.html#method_exceptionHandler[exceptionHandler]`

[source,php]
----
<?php

    // setting handler for errors
    $consumer->exceptionHandler(function ($e) {
        echo "Error = ".$e->getMessage()."\n";
    });

----

== Automatic clean-up in verticles

If you’re creating consumers and producer from inside verticles, those consumers and producers will be automatically
closed when the verticle is undeployed.

== Using Vert.x serializers/deserizaliers

Vert.x Kafka client comes out of the box with serializers and deserializers for buffers, json object
and json array.

In a consumer you can use buffers

[source,php]
----
<?php

    // Creating a consumer able to deserialize to buffers
    $config = array();
    $config["bootstrap.servers"] = "localhost:9092";
    $config["key.deserializer"] = "io.vertx.kafka.client.serialization.BufferDeserializer";
    $config["value.deserializer"] = "io.vertx.kafka.client.serialization.BufferDeserializer";
    $config["group.id"] = "my_group";
    $config["auto.offset.reset"] = "earliest";
    $config["enable.auto.commit"] = "false";

    // Creating a consumer able to deserialize to json object
    $config = array();
    $config["bootstrap.servers"] = "localhost:9092";
    $config["key.deserializer"] = "io.vertx.kafka.client.serialization.JsonObjectDeserializer";
    $config["value.deserializer"] = "io.vertx.kafka.client.serialization.JsonObjectDeserializer";
    $config["group.id"] = "my_group";
    $config["auto.offset.reset"] = "earliest";
    $config["enable.auto.commit"] = "false";

    // Creating a consumer able to deserialize to json array
    $config = array();
    $config["bootstrap.servers"] = "localhost:9092";
    $config["key.deserializer"] = "io.vertx.kafka.client.serialization.JsonArrayDeserializer";
    $config["value.deserializer"] = "io.vertx.kafka.client.serialization.JsonArrayDeserializer";
    $config["group.id"] = "my_group";
    $config["auto.offset.reset"] = "earliest";
    $config["enable.auto.commit"] = "false";

----

Or in a producer

[source,php]
----
<?php

    // Creating a producer able to serialize to buffers
    $config = array();
    $config["bootstrap.servers"] = "localhost:9092";
    $config["key.serializer"] = "io.vertx.kafka.client.serialization.BufferSerializer";
    $config["value.serializer"] = "io.vertx.kafka.client.serialization.BufferSerializer";
    $config["acks"] = "1";

    // Creating a producer able to serialize to json object
    $config = array();
    $config["bootstrap.servers"] = "localhost:9092";
    $config["key.serializer"] = "io.vertx.kafka.client.serialization.JsonObjectSerializer";
    $config["value.serializer"] = "io.vertx.kafka.client.serialization.JsonObjectSerializer";
    $config["acks"] = "1";

    // Creating a producer able to serialize to json array
    $config = array();
    $config["bootstrap.servers"] = "localhost:9092";
    $config["key.serializer"] = "io.vertx.kafka.client.serialization.JsonArraySerializer";
    $config["value.serializer"] = "io.vertx.kafka.client.serialization.JsonArraySerializer";
    $config["acks"] = "1";

----

ifdef::java,groovy,kotlin[]
You can also specify the serizalizers/deserializers at creation time:

In a consumer

[source,php]
----
Code not translatable
----

Or in a producer

[source,php]
----
Code not translatable
----

endif::[]

include::override/rxjava.adoc[]

ifdef::java,groovy,kotlin[]
== Stream implementation and native Kafka objects

When you want to operate on native Kafka records you can use a stream oriented
implementation which handles native Kafka objects.

The `KafkaReadStream` shall be used for reading topic partitions, it is
a read stream of `ConsumerRecord` objects.

The `KafkaWriteStream` shall be used for writing to topics, it is a write
stream of `ProducerRecord`.

The API exposed by these interfaces is mostly the same than the polyglot version.
endif::[]

include::admin.adoc[]